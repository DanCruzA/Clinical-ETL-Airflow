# üß™ Automated Clinical Lab ETL Pipeline (Airflow + Docker)

## üìã Descripci√≥n del Proyecto
Este proyecto consiste en un **Pipeline de Ingenier√≠a de Datos End-to-End** que automatiza la ingesta, limpieza y carga de resultados de laboratorio cl√≠nico masivos.

Se construy√≥ una arquitectura contenerizada utilizando **Docker**, donde **Apache Airflow** orquesta el flujo de datos (DAGs), procesando archivos crudos con **Pandas** y carg√°ndolos en un Data Warehouse en **PostgreSQL**.

## üèóÔ∏è Arquitectura de la Soluci√≥n

```mermaid
graph LR
    A[Generador de Datos<br>Script Python] -->|CSV Raw| B(Sistema de Archivos)
    B --> C{Apache Airflow<br>Orquestador}
    C -->|Extract & Transform<br>Pandas| D[Limpieza de Datos]
    D -->|Load| E[(PostgreSQL<br>Data Warehouse)]

. Fuente: Datos simulados de laboratorio (5,000 registros con ruido/errores intencionales).

. Transformaci√≥n: Normalizaci√≥n de valores negativos, imputaci√≥n de nulos y tipado de datos.

. Infraestructura: Despliegue mediante docker-compose con servicios aislados.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

. Docker & Docker Compose: Para la infraestructura como c√≥digo (IaC).

. Apache Airflow 2.9: Para la orquestaci√≥n y calendarizaci√≥n de tareas.

. Python 3.10 (Pandas/SQLAlchemy): Motor de procesamiento ETL.

. PostgreSQL 16: Base de datos destino.

. Linux (Pop!_OS): Entorno de desarrollo.

## üîß Desaf√≠os T√©cnicos y Soluciones (Troubleshooting)
Durante la implementaci√≥n de este pipeline en un entorno Linux estricto, se superaron los siguientes retos t√©cnicos:

1. Gesti√≥n de Dependencias en Contenedores (Custom Image)
Problema: La imagen base de Airflow no incluye librer√≠as de ciencia de datos (pandas, sqlalchemy), causando fallos en la ejecuci√≥n de tareas (ModuleNotFoundError). Soluci√≥n: En lugar de instalar librer√≠as manualmente en tiempo de ejecuci√≥n, se implement√≥ una imagen personalizada mediante un Dockerfile para garantizar la reproducibilidad.

C√≥digo implementado (Dockerfile):

FROM apache/airflow:2.9.1
# Instalaci√≥n de dependencias al construir la imagen
RUN pip install --no-cache-dir pandas sqlalchemy psycopg2-binary

2. Conflictos de Permisos en Vol√∫menes (Linux)
Problema: Al mapear vol√∫menes locales (./logs, ./data) al contenedor, Airflow (UID 50000) no ten√≠a permisos de escritura sobre las carpetas del host (usuario local), generando errores PermissionError: [Errno 13]. Soluci√≥n: Se aplic√≥ una apertura de permisos recursiva en el entorno de desarrollo para permitir que el contenedor escribiera los logs de ejecuci√≥n.

Comando de soluci√≥n:

sudo chmod -R 777 dags data logs

## üöÄ C√≥mo ejecutar este proyecto

Clonar el repositorio:

git clone [https://github.com/DanCruzA/Clinical-ETL-Airflow.git](https://github.com/DanCruzA/Clinical-ETL-Airflow.git)
cd Clinical-ETL-Airflow

Generar la Data Simulada:

python3 generar_data.py

Desplegar la Infraestructura:

# El flag --build es importante para crear la imagen con Pandas
docker-compose up --build -d

Acceder a Airflow:

. URL: http://localhost:8085

. Credenciales: admin / admin

. Activar el DAG etl_laboratorio_clinico.

## üìä Verificaci√≥n de Datos
Una vez ejecutado el pipeline, se puede verificar la carga en el Data Warehouse:

-- Verificar correcci√≥n de valores negativos y conteo total
SELECT count(*) FROM fact_resultados_lab;
-- Resultado esperado: 5000